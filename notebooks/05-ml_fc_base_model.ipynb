{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b35c11e",
   "metadata": {},
   "source": [
    "# Base Model for Demand Forecasting\n",
    "\n",
    "The main objective is to optimize inventory and purchasing management, with a target of **reducing overstocking by 20%** within 6 months.\n",
    "\n",
    "- Target Variable for Inventory Optimization: **stock_quantity**\n",
    "- Target Variable for Demand Forecasting: **y**\n",
    "\n",
    "### Metrics for models avaliation\n",
    "- RMSE - Root Mean Squared Error\n",
    "- MAE - Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa395cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to control baseline training\n",
    "TRAIN_BASE = False\n",
    "\n",
    "# Flag to control hyperparameter search\n",
    "TRAIN_SEARCH = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecca068",
   "metadata": {},
   "source": [
    "# DATA ACQUISITION\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e552247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.express as px\n",
    "from functools import reduce\n",
    "\n",
    "# Specialized Libraries\n",
    "import mlflow\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.client import MlflowClient\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.target_transforms import AutoDifferences, LocalRobustScaler \n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean\n",
    "from mlforecast.feature_engineering import transform_exog\n",
    "from mlforecast.auto import AutoLinearRegression, AutoRidge, AutoRandomForest, AutoXGBoost\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import smape, rmse, mae\n",
    "from utilsforecast.plotting import plot_series\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# To import customized class and function\n",
    "from smart_supply_chain_ai.utils.preprocess_functions import SimplePreprocessor, XDFPreparator\n",
    "\n",
    "# Notebook mlflow Loggings\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b4383",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ab326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_path = os.path.join('..', 'data', 'processed')\n",
    "docs_path = os.path.join('..', 'docs')\n",
    "path_models = os.path.join('..', 'models')\n",
    "json_path = os.path.join('../src','smart_supply_chain_ai' , 'utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f3effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pickle file\n",
    "compare_data = pd.read_pickle(data_path + '/data_for_compare.pkl')\n",
    "read_data = pd.read_pickle(data_path + '/data_for_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a01c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of the data\n",
    "df = read_data.copy()\n",
    "df_compare = compare_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21618135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>received_date</th>\n",
       "      <th>lpo</th>\n",
       "      <th>in_season</th>\n",
       "      <th>product</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>shelf_life_days</th>\n",
       "      <th>maximum_days_on_sale</th>\n",
       "      <th>unit_of_measurement</th>\n",
       "      <th>supplier_rating</th>\n",
       "      <th>supplier</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>moq</th>\n",
       "      <th>storage_recommendation</th>\n",
       "      <th>temperature_classification</th>\n",
       "      <th>precipitation_classification</th>\n",
       "      <th>wind_classification</th>\n",
       "      <th>weather_severity</th>\n",
       "      <th>day_classification</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>sales_demand</th>\n",
       "      <th>sales_volume</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>min_stock</th>\n",
       "      <th>max_stock</th>\n",
       "      <th>stock_quantity</th>\n",
       "      <th>delivery_lag</th>\n",
       "      <th>expiration_status</th>\n",
       "      <th>inventory_turnover_rate</th>\n",
       "      <th>doi_inventory_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70876</th>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>False</td>\n",
       "      <td>All-Purpose Flour</td>\n",
       "      <td>1940872|P</td>\n",
       "      <td>Pantry</td>\n",
       "      <td>Baking Supplies</td>\n",
       "      <td>365.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>lb</td>\n",
       "      <td>3</td>\n",
       "      <td>BakeWell Supplies</td>\n",
       "      <td>1552913|S</td>\n",
       "      <td>90.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Room Temperature</td>\n",
       "      <td>Mild to Temperate</td>\n",
       "      <td>No precipitation</td>\n",
       "      <td>Calm / Light Breeze</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Normal</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>Safe</td>\n",
       "      <td>28.095371</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70877</th>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>False</td>\n",
       "      <td>Popcorn Kernels</td>\n",
       "      <td>1992802|P</td>\n",
       "      <td>Pantry</td>\n",
       "      <td>Snacks</td>\n",
       "      <td>365.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>lb</td>\n",
       "      <td>4</td>\n",
       "      <td>SnackTime Distributors</td>\n",
       "      <td>1414750|S</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Room Temperature</td>\n",
       "      <td>Mild to Temperate</td>\n",
       "      <td>No precipitation</td>\n",
       "      <td>Calm / Light Breeze</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Normal</td>\n",
       "      <td>135</td>\n",
       "      <td>4</td>\n",
       "      <td>848</td>\n",
       "      <td>1060</td>\n",
       "      <td>1342</td>\n",
       "      <td>7</td>\n",
       "      <td>Safe</td>\n",
       "      <td>25.934508</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70878</th>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>False</td>\n",
       "      <td>Plum</td>\n",
       "      <td>1998069|P</td>\n",
       "      <td>Fresh Foods</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>lb</td>\n",
       "      <td>4</td>\n",
       "      <td>Stone Fruit Specialists</td>\n",
       "      <td>1405032|S</td>\n",
       "      <td>165.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Refrigerated</td>\n",
       "      <td>Mild to Temperate</td>\n",
       "      <td>No precipitation</td>\n",
       "      <td>Calm / Light Breeze</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weekdays</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Normal</td>\n",
       "      <td>754</td>\n",
       "      <td>6</td>\n",
       "      <td>6156</td>\n",
       "      <td>7182</td>\n",
       "      <td>6187</td>\n",
       "      <td>2</td>\n",
       "      <td>Safe</td>\n",
       "      <td>19.178620</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      received_date        lpo  in_season            product product_id  \\\n",
       "70876    2025-05-09 2025-05-04      False  All-Purpose Flour  1940872|P   \n",
       "70877    2025-05-09 2025-05-02      False    Popcorn Kernels  1992802|P   \n",
       "70878    2025-05-09 2025-05-07      False               Plum  1998069|P   \n",
       "\n",
       "          category     sub_category  shelf_life_days  maximum_days_on_sale  \\\n",
       "70876       Pantry  Baking Supplies            365.0                  60.0   \n",
       "70877       Pantry           Snacks            365.0                  90.0   \n",
       "70878  Fresh Foods           Fruits              5.0                   2.0   \n",
       "\n",
       "      unit_of_measurement supplier_rating                 supplier  \\\n",
       "70876                  lb               3        BakeWell Supplies   \n",
       "70877                  lb               4   SnackTime Distributors   \n",
       "70878                  lb               4  Stone Fruit Specialists   \n",
       "\n",
       "      supplier_id  distance_km    moq storage_recommendation  \\\n",
       "70876   1552913|S         90.0   50.0       Room Temperature   \n",
       "70877   1414750|S         80.0  110.0       Room Temperature   \n",
       "70878   1405032|S        165.0   38.0           Refrigerated   \n",
       "\n",
       "      temperature_classification precipitation_classification  \\\n",
       "70876          Mild to Temperate             No precipitation   \n",
       "70877          Mild to Temperate             No precipitation   \n",
       "70878          Mild to Temperate             No precipitation   \n",
       "\n",
       "       wind_classification weather_severity day_classification  is_holiday  \\\n",
       "70876  Calm / Light Breeze           Normal           Weekdays       False   \n",
       "70877  Calm / Light Breeze           Normal           Weekdays       False   \n",
       "70878  Calm / Light Breeze           Normal           Weekdays       False   \n",
       "\n",
       "       is_weekend sales_demand  sales_volume  lead_time  min_stock  max_stock  \\\n",
       "70876       False       Normal             9          5         44         55   \n",
       "70877       False       Normal           135          4        848       1060   \n",
       "70878       False       Normal           754          6       6156       7182   \n",
       "\n",
       "       stock_quantity  delivery_lag expiration_status  \\\n",
       "70876              51             5              Safe   \n",
       "70877            1342             7              Safe   \n",
       "70878            6187             2              Safe   \n",
       "\n",
       "       inventory_turnover_rate  doi_inventory_turnover  \n",
       "70876                28.095371                    36.0  \n",
       "70877                25.934508                    39.0  \n",
       "70878                19.178620                    53.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View historical data\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8730360c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>received_date</th>\n",
       "      <th>lpo</th>\n",
       "      <th>in_season</th>\n",
       "      <th>product</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>shelf_life_days</th>\n",
       "      <th>maximum_days_on_sale</th>\n",
       "      <th>unit_of_measurement</th>\n",
       "      <th>supplier_rating</th>\n",
       "      <th>supplier</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>moq</th>\n",
       "      <th>storage_recommendation</th>\n",
       "      <th>temperature_classification</th>\n",
       "      <th>precipitation_classification</th>\n",
       "      <th>wind_classification</th>\n",
       "      <th>weather_severity</th>\n",
       "      <th>day_classification</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>sales_demand</th>\n",
       "      <th>sales_volume</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>min_stock</th>\n",
       "      <th>max_stock</th>\n",
       "      <th>stock_quantity</th>\n",
       "      <th>delivery_lag</th>\n",
       "      <th>expiration_status</th>\n",
       "      <th>inventory_turnover_rate</th>\n",
       "      <th>doi_inventory_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70879</th>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>False</td>\n",
       "      <td>Arborio Rice</td>\n",
       "      <td>1003530|P</td>\n",
       "      <td>Pantry</td>\n",
       "      <td>Grains &amp; Rice</td>\n",
       "      <td>730.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>lb</td>\n",
       "      <td>4</td>\n",
       "      <td>GrainWorld Distributors</td>\n",
       "      <td>1792439|S</td>\n",
       "      <td>150.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Room Temperature</td>\n",
       "      <td>Mild to Temperate</td>\n",
       "      <td>No precipitation</td>\n",
       "      <td>Calm / Light Breeze</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>High</td>\n",
       "      <td>186</td>\n",
       "      <td>5</td>\n",
       "      <td>468</td>\n",
       "      <td>585</td>\n",
       "      <td>662</td>\n",
       "      <td>10</td>\n",
       "      <td>Safe</td>\n",
       "      <td>28.680627</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70880</th>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>False</td>\n",
       "      <td>Canned Tomatoes</td>\n",
       "      <td>1007004|P</td>\n",
       "      <td>Pantry</td>\n",
       "      <td>Canned Goods</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>unit</td>\n",
       "      <td>2</td>\n",
       "      <td>Wholesale Warehouse</td>\n",
       "      <td>1363063|S</td>\n",
       "      <td>25.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Room Temperature</td>\n",
       "      <td>Mild to Temperate</td>\n",
       "      <td>No precipitation</td>\n",
       "      <td>Calm / Light Breeze</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>High</td>\n",
       "      <td>243</td>\n",
       "      <td>4</td>\n",
       "      <td>285</td>\n",
       "      <td>380</td>\n",
       "      <td>308</td>\n",
       "      <td>5</td>\n",
       "      <td>Safe</td>\n",
       "      <td>64.442801</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70881</th>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>False</td>\n",
       "      <td>Canned Tuna</td>\n",
       "      <td>1017723|P</td>\n",
       "      <td>Pantry</td>\n",
       "      <td>Canned Fish</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>unit</td>\n",
       "      <td>4</td>\n",
       "      <td>PantryEssentials Ltd.</td>\n",
       "      <td>1141220|S</td>\n",
       "      <td>95.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Room Temperature</td>\n",
       "      <td>Mild to Temperate</td>\n",
       "      <td>No precipitation</td>\n",
       "      <td>Calm / Light Breeze</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>High</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>130</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>Safe</td>\n",
       "      <td>17.540236</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      received_date        lpo  in_season          product product_id  \\\n",
       "70879    2025-05-11 2025-05-01      False     Arborio Rice  1003530|P   \n",
       "70880    2025-05-11 2025-05-06      False  Canned Tomatoes  1007004|P   \n",
       "70881    2025-05-11 2025-05-05      False      Canned Tuna  1017723|P   \n",
       "\n",
       "      category   sub_category  shelf_life_days  maximum_days_on_sale  \\\n",
       "70879   Pantry  Grains & Rice            730.0                 180.0   \n",
       "70880   Pantry   Canned Goods           1095.0                  90.0   \n",
       "70881   Pantry    Canned Fish           1095.0                  90.0   \n",
       "\n",
       "      unit_of_measurement supplier_rating                 supplier  \\\n",
       "70879                  lb               4  GrainWorld Distributors   \n",
       "70880                unit               2      Wholesale Warehouse   \n",
       "70881                unit               4    PantryEssentials Ltd.   \n",
       "\n",
       "      supplier_id  distance_km    moq storage_recommendation  \\\n",
       "70879   1792439|S        150.0  200.0       Room Temperature   \n",
       "70880   1363063|S         25.0  300.0       Room Temperature   \n",
       "70881   1141220|S         95.0  130.0       Room Temperature   \n",
       "\n",
       "      temperature_classification precipitation_classification  \\\n",
       "70879          Mild to Temperate             No precipitation   \n",
       "70880          Mild to Temperate             No precipitation   \n",
       "70881          Mild to Temperate             No precipitation   \n",
       "\n",
       "       wind_classification weather_severity day_classification  is_holiday  \\\n",
       "70879  Calm / Light Breeze           Normal             Sunday       False   \n",
       "70880  Calm / Light Breeze           Normal             Sunday       False   \n",
       "70881  Calm / Light Breeze           Normal             Sunday       False   \n",
       "\n",
       "       is_weekend sales_demand  sales_volume  lead_time  min_stock  max_stock  \\\n",
       "70879        True         High           186          5        468        585   \n",
       "70880        True         High           243          4        285        380   \n",
       "70881        True         High            25          4         56        130   \n",
       "\n",
       "       stock_quantity  delivery_lag expiration_status  \\\n",
       "70879             662            10              Safe   \n",
       "70880             308             5              Safe   \n",
       "70881              89             6              Safe   \n",
       "\n",
       "       inventory_turnover_rate  doi_inventory_turnover  \n",
       "70879                28.680627                    35.0  \n",
       "70880                64.442801                    15.0  \n",
       "70881                17.540236                    58.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View compare data\n",
    "df_compare.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e1d9c",
   "metadata": {},
   "source": [
    "# Prepare Data for Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9112b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for mlforecast compatibility\n",
    "df.rename(columns={'received_date':'ds', 'product_id': 'unique_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77fd948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Encode categorical columns\n",
    "df[['category_encoded', 'sub_category_encoded', 'weather_severity_encoded']] = df[['category', 'sub_category', 'weather_severity']].apply(lambda col: le.fit_transform(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b2229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for sales volume forecasting\n",
    "sales_df = df[['ds',\n",
    " 'unique_id',\n",
    " 'in_season',\n",
    " 'category_encoded',\n",
    " 'sub_category_encoded',\n",
    " 'shelf_life_days',\n",
    " 'stock_quantity',\n",
    " 'sales_volume',\n",
    " ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ffd9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename target column\n",
    "sales_df.rename(columns={'sales_volume': 'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "402d8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ds' column to datetime format\n",
    "sales_df['ds'] = pd.to_datetime(sales_df['ds'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96179f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for all numeric columns\n",
    "correlation_matrix = sales_df.select_dtypes(exclude=['category', 'object', 'datetime']).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f885041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a heatmap visualization of the correlation matrix\n",
    "corr1 = correlation_matrix[correlation_matrix >= 0.7].replace(1.0, np.nan).dropna(how='all', axis=1)\n",
    "corr1.dropna(how='all').replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4188ab24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "in_season",
          "category_encoded",
          "sub_category_encoded",
          "shelf_life_days",
          "stock_quantity",
          "y"
         ],
         "xaxis": "x",
         "y": [
          "in_season",
          "category_encoded",
          "sub_category_encoded",
          "shelf_life_days",
          "stock_quantity",
          "y"
         ],
         "yaxis": "y",
         "z": [
          [
           null,
           null,
           null,
           null,
           null,
           null
          ],
          [
           -0.1091078136197234,
           null,
           null,
           null,
           null,
           null
          ],
          [
           0.26227246462983556,
           -0.03362732197796215,
           null,
           null,
           null,
           null
          ],
          [
           -0.21630325449667615,
           0.5485607430961312,
           -0.19876049589377515,
           null,
           null,
           null
          ],
          [
           0.443477700350228,
           -0.2970635458051045,
           0.11473719395470973,
           -0.4144957573505867,
           null,
           null
          ],
          [
           0.45622448664308296,
           -0.2909652593692749,
           0.11188327974558936,
           -0.36671779027838897,
           0.6756646186720714,
           null
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmax": 1,
         "cmin": -1,
         "colorscale": [
          [
           0,
           "rgb(5,48,97)"
          ],
          [
           0.1,
           "rgb(33,102,172)"
          ],
          [
           0.2,
           "rgb(67,147,195)"
          ],
          [
           0.3,
           "rgb(146,197,222)"
          ],
          [
           0.4,
           "rgb(209,229,240)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(253,219,199)"
          ],
          [
           0.7,
           "rgb(244,165,130)"
          ],
          [
           0.8,
           "rgb(214,96,77)"
          ],
          [
           0.9,
           "rgb(178,24,43)"
          ],
          [
           1,
           "rgb(103,0,31)"
          ]
         ]
        },
        "height": 800,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Correlation Matrix - Sales Volume"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hide the top half of the matrix to avoid repeating values\n",
    "mask = np.tril(np.ones(correlation_matrix.shape), k=-1)\n",
    "masked_corr = correlation_matrix.where(mask == 1)\n",
    "\n",
    "# Create a heatmap visualization of the correlation matrix\n",
    "fig_corr = px.imshow(masked_corr,\n",
    "                    title='Correlation Matrix - Sales Volume',\n",
    "                    color_continuous_scale='RdBu_r',  # Red-Blue reversed color scale\n",
    "                    aspect=\"auto\",                   # Automatic aspect ratio\n",
    "                    text_auto=True,                 # Display correlation values on cells\n",
    "                    zmin=-1, zmax=1)                 # Fix color scale from -1 to +1\n",
    "\n",
    "# Adjust the figure dimensions\n",
    "fig_corr.update_layout(width=800, height=800)\n",
    "\n",
    "# Display the interactive heatmap\n",
    "fig_corr.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e1d2c",
   "metadata": {},
   "source": [
    "# Setup Machine Learning Model's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdbc5f",
   "metadata": {},
   "source": [
    "## Applying Feature Engineering and Partitioning Data for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a73d4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to maintain\n",
    "maintain_cols = ['received_date', 'product', 'product_id', 'sales_volume', 'category', 'sub_category', 'is_holiday', 'in_season', 'shelf_life_days', 'stock_quantity']\n",
    "\n",
    "# Define column renaming pattern\n",
    "pattern = {'received_date': 'ds', 'product_id': 'unique_id', 'sales_volume': 'y'}\n",
    "\n",
    "# Select relevant columns from the dataset\n",
    "select_df = read_data[maintain_cols].rename(columns=pattern)\n",
    "df_future_exog = compare_data[maintain_cols].rename(columns=pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4491564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5380"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many rows have the same ds and unique_id\n",
    "select_df.duplicated(subset=['ds', 'unique_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbbca1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by the 'ds' column and reset the index, dropping the old index\n",
    "select_df = select_df.sort_values(by='ds').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0212682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group both DataFrames by ds and unique_id, then apply aggregation rules to each column\n",
    "agg_rules = {\n",
    "    'y': 'sum',\n",
    "    'category': 'last',\n",
    "    'sub_category': 'last',\n",
    "    'is_holiday': 'last',\n",
    "    'in_season': 'last',\n",
    "    'shelf_life_days': 'last',\n",
    "    'stock_quantity': 'first',\n",
    "    'product': 'first',\n",
    "}\n",
    "\n",
    "select_df = select_df.groupby(['ds', 'unique_id'], as_index=False).agg(agg_rules).reset_index(drop=True)\n",
    "df_future_exog = df_future_exog.groupby(['ds', 'unique_id'], as_index=False).agg(agg_rules).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30f470c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in select_df: 0\n",
      "Duplicates in compare_data: 0\n"
     ]
    }
   ],
   "source": [
    "# Verify duplicates after Partitioning\n",
    "print(f\"Duplicates in select_df: {select_df.duplicated(subset=['ds', 'unique_id']).sum()}\")\n",
    "print(f\"Duplicates in compare_data: {df_future_exog.duplicated(subset=['ds', 'unique_id']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c01c65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_exogenous_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Generate lag-based features from the selected dataframe\n",
    "    exog_feat = transform_exog(\n",
    "        data[['ds', 'unique_id', 'stock_quantity']],  # Use only the relevant columns\n",
    "        lags=[1, 2, 7],  # Create lag features for 1, 2, and 7 time steps\n",
    "        lag_transforms={\n",
    "            1: [ExpandingMean()],         # Apply expanding mean on lag 1\n",
    "            7: [RollingMean(window_size=7)]  # Apply 7-day rolling mean on lag 7\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Remove the original 'stock_quantity' column to avoid duplication\n",
    "    exog_feat = exog_feat.drop(columns='stock_quantity')\n",
    "\n",
    "    # Merge the generated exogenous features back into the main dataframe\n",
    "    data_merged = data.merge(exog_feat, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "    # Drop NaNs\n",
    "    return data_merged.dropna().drop(columns='stock_quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "197d1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = transform_exogenous_features(select_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53752c9",
   "metadata": {},
   "source": [
    "## Set Up MLForecast Models to Predict Sales Volume on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb344af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# +++ Prepare MLForecast +++\n",
    "# Initialize the temporal preprocessing pipeline with a specified pattern and static features\n",
    "preprocessor = SimplePreprocessor()\n",
    "\n",
    "# Configure model parameters\n",
    "random_state = 42\n",
    "params_rf = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_features\": \"sqrt\",\n",
    "}\n",
    "params_xgb = {\n",
    "    'objective':'reg:squarederror',  \n",
    "    'n_estimators':200,              \n",
    "    'learning_rate':0.1,             \n",
    "    'max_depth':6,                   \n",
    "    'subsample':0.8,                 \n",
    "    'colsample_bytree':0.8,          \n",
    "}\n",
    "\n",
    "# Define Models Pipelines\n",
    "pipes_models = {\n",
    "    'linear': make_pipeline(preprocessor, LinearRegression()),\n",
    "    'ridge': make_pipeline(preprocessor, Ridge()),\n",
    "    'rf': make_pipeline(preprocessor, RandomForestRegressor(**params_rf, random_state=random_state)),\n",
    "    'xgb': make_pipeline(preprocessor, XGBRegressor(**params_xgb, random_state=random_state))\n",
    "}\n",
    "\n",
    "# Define target transformations\n",
    "target_transforms = [\n",
    "    AutoDifferences(3),           \n",
    "    LocalRobustScaler(scale='iqr')\n",
    "    ]\n",
    "\n",
    "# Define series transformations\n",
    "lag_transforms = {\n",
    "    1: [ExpandingMean()],              # Aplica ExpandingMean ao lag 1\n",
    "    2: [RollingMean(window_size=2)],   # Aplica RollingMean(2) ao lag 2\n",
    "    7: [RollingMean(window_size=7)],   # Aplica RollingMean(7) ao lag 7\n",
    "}\n",
    "\n",
    "lags=[1, 2, 7]\n",
    "date_features=['dayofweek', 'month']\n",
    "num_threads=4\n",
    "\n",
    "# Configure MLforecast for model training with temporal feature engineering\n",
    "fcst = MLForecast(\n",
    "    models=pipes_models,\n",
    "    freq='D',\n",
    "    lags=lags,\n",
    "    lag_transforms=lag_transforms,\n",
    "    date_features=date_features,\n",
    "    num_threads=num_threads,\n",
    "    target_transforms=target_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395720ef",
   "metadata": {},
   "source": [
    "# Start Mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "897af7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/19 19:35:21 INFO mlflow.tracking.fluent: Experiment with name 'Demand_Forecasting_Base_Line' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/rb/Projects/portfolio/smart-supply-chain-ai/notebooks/../models/mlflow_data/630183622070888025', creation_time=1763591721374, experiment_id='630183622070888025', last_update_time=1763591721374, lifecycle_stage='active', name='Demand_Forecasting_Base_Line', tags={}>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLflow experiment setup\n",
    "mlflow.set_tracking_uri(\"file:../models/mlflow_data\")\n",
    "mlflow.set_experiment(\"Demand_Forecasting_Base_Line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5983f6f",
   "metadata": {},
   "source": [
    "### Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afa3366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction length\n",
    "horizon = 28\n",
    "\n",
    "# Frequency (month, year, day, min, e.g.)\n",
    "freq = 'D'\n",
    "\n",
    "# Define static columns\n",
    "static_ = ['category', 'sub_category', 'shelf_life_days']\n",
    "\n",
    "# Split data into train and validation\n",
    "splitted_df = select_df.groupby('unique_id').tail(horizon)\n",
    "X_df = splitted_df.drop(columns=['y'] + static_)\n",
    "valid = splitted_df[['ds', 'unique_id', 'y']]\n",
    "train = select_df.drop(splitted_df.index).drop(columns=['product'])\n",
    "# df_future_exog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8042260",
   "metadata": {},
   "source": [
    "### Parameters MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76b27da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models parameters\n",
    "model_params = {\n",
    "    'rf': params_rf,\n",
    "    'xgb': params_xgb,\n",
    "    'linear': {},\n",
    "    'ridge': {},\n",
    "}\n",
    "\n",
    "# MLforecast parameters initialization\n",
    "lag_transforms_log = {\n",
    "    k: [t.__class__.__name__ for t in v] \n",
    "    for k, v in lag_transforms.items()\n",
    "}\n",
    "target_transforms_log = [t.__class__.__name__ for t in target_transforms]\n",
    "\n",
    "init_params = {\n",
    "    'freq': fcst.freq,\n",
    "    'lags': lags,\n",
    "    'lag_transforms': lag_transforms_log,\n",
    "    'date_features': date_features,\n",
    "    'target_transforms': target_transforms_log,\n",
    "    'num_threads': num_threads,\n",
    "}\n",
    "\n",
    "# Preprocessor parameters\n",
    "preprocessor_params = {\n",
    "    'static_features': preprocessor.static_features,\n",
    "    'imputer_cat': 'most_frequent',\n",
    "    'imputer_num': 'median',\n",
    "    'scaler_num': 'PowerTransformer(yeo-johnson)',\n",
    "}\n",
    "\n",
    "# Concat for MLflow\n",
    "mlflow_params = {\n",
    "    'MLForecast_init': init_params,\n",
    "    'Preprocessor': preprocessor_params,\n",
    "    'Modelos': model_params,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3adb3979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models...\n",
      "Creating future DataFrame...\n",
      "Predicting...\n",
      "Evaluating models...\n",
      "Metrics summary:\n",
      "     unique_id metric     linear      ridge         rf        xgb\n",
      "0    1003530|P   rmse  73.103644  73.103867  76.973090  76.356942\n",
      "1    1007004|P   rmse  86.357853  86.359719  83.526162  82.255408\n",
      "2    1009699|P   rmse  34.207649  34.207791  30.824450  31.976865\n",
      "3    1017723|P   rmse   7.977720   7.977247   6.295355   6.628097\n",
      "4    1018159|P   rmse  71.205105  71.227422  82.966885  82.227393\n",
      "..         ...    ...        ...        ...        ...        ...\n",
      "505  1945145|P  smape   0.293177   0.293177   0.215536   0.232225\n",
      "506  1964630|P  smape   0.235770   0.235823   0.163848   0.182403\n",
      "507  1992802|P  smape   0.151282   0.151270   0.159906   0.161418\n",
      "508  1996239|P  smape   0.180934   0.180931   0.129989   0.130294\n",
      "509  1998069|P  smape   0.150584   0.150596   0.142048   0.140978\n",
      "\n",
      "[510 rows x 6 columns]\n",
      "\n",
      "--- Log para o Modelo: linear ---\n",
      "\n",
      "--- Log para o Modelo: rf ---\n",
      "\n",
      "--- Log para o Modelo: ridge ---\n",
      "\n",
      "--- Log para o Modelo: xgb ---\n",
      "Best Model: rf with RMSE: 236.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/19 19:39:57 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Successfully registered model 'BestBaselineModel'.\n",
      "Created version '1' of model 'BestBaselineModel'.\n"
     ]
    }
   ],
   "source": [
    "# Best model registration name\n",
    "REGISTERED_MODEL_NAME = \"BestBaselineModel\"\n",
    "\n",
    "if TRAIN_BASE:\n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run(run_name='MLForescast_Base_line_model') as run:\n",
    "        ## Parameters Log\n",
    "        # Log Generic parameters\n",
    "        mlflow.log_params(mlflow_params['MLForecast_init'])\n",
    "        mlflow.log_params(mlflow_params['Preprocessor'])\n",
    "\n",
    "        # Log specific parameter for each model\n",
    "        for model_name, params in mlflow_params['Modelos'].items():\n",
    "            # Add prefix in MLflow UI (e.g.: 'model_rf_n_estimators')\n",
    "            prefixed_params = {f\"model_{model_name}_{k}\": v for k, v in params.items()}\n",
    "            mlflow.log_params(prefixed_params)\n",
    "\n",
    "        ## Train and Predict\n",
    "        # Train models\n",
    "        print('Training models...')\n",
    "        fcst.fit(train, static_features=static_)\n",
    "\n",
    "        # Log expected features\n",
    "        first_model_name = list(fcst.models_.keys())[0]\n",
    "        model_pipeline = fcst.models_[first_model_name]\n",
    "\n",
    "        preprocessor = None\n",
    "        if hasattr(model_pipeline, 'named_steps'):\n",
    "            for step_name in ['preprocessor', 'columntransformer', 'simplepreprocessor']:\n",
    "                preprocessor = model_pipeline.named_steps.get(step_name)\n",
    "                if preprocessor:\n",
    "                    break\n",
    "\n",
    "        feature_source = preprocessor or model_pipeline\n",
    "        if hasattr(feature_source, 'get_feature_names_out'):\n",
    "            feature_names = feature_source.get_feature_names_out().tolist()\n",
    "            mlflow.log_param(\"expected_features\", feature_names)\n",
    "        else:\n",
    "            original_features = train.drop(columns=['y']).columns.tolist()\n",
    "            mlflow.log_param(\"original_features\", original_features)\n",
    "\n",
    "        # Make Future DataFrame\n",
    "        print('Creating future DataFrame...')\n",
    "        future_df = fcst.make_future_dataframe(h=horizon)\n",
    "\n",
    "        # Initialise Preparator\n",
    "        preparator = XDFPreparator(exog_df=X_df, json_path=json_path)\n",
    "\n",
    "        # Create Exogenous Features\n",
    "        X_df = preparator.create_future_df(future_df)\n",
    "\n",
    "        # Predict\n",
    "        print('Predicting...')\n",
    "        predictions_df = fcst.predict(h=horizon, X_df=X_df)\n",
    "\n",
    "        # Evaluation\n",
    "        print('Evaluating models...')\n",
    "        evaluation_df = predictions_df.merge(valid[['unique_id', 'ds', 'y']], on=['unique_id', 'ds'])\n",
    "\n",
    "        # Consolidate Evaluation\n",
    "        metrics = evaluate(\n",
    "            df=evaluation_df,\n",
    "            metrics=[rmse, mae, smape],\n",
    "            models=predictions_df.columns.drop(['unique_id', 'ds']).tolist(),\n",
    "            id_col='unique_id',\n",
    "            time_col='ds',\n",
    "            target_col='y'\n",
    "        )\n",
    "\n",
    "\n",
    "        print('Metrics summary:')\n",
    "        print(metrics)\n",
    "\n",
    "        # Metric calculation\n",
    "        best_rmse = float('inf')\n",
    "        best_model_name = None\n",
    "\n",
    "        # Wide to long\n",
    "        metrics_long = pd.melt(metrics, \n",
    "                            id_vars=['unique_id', 'metric'], \n",
    "                            value_vars=['linear', 'ridge', 'rf', 'xgb'],\n",
    "                            var_name='model', \n",
    "                            value_name='value')\n",
    "\n",
    "\n",
    "        # Pivot for metrics in columns\n",
    "        metrics_pivot = metrics_long.pivot_table(index=['unique_id', 'model'], \n",
    "                                                columns='metric', \n",
    "                                                values='value').reset_index()\n",
    "\n",
    "        # Define the aggregation functions we want to apply (mean, std, median)\n",
    "        agg_funcs = {\n",
    "            \"mean\": \"mean\",\n",
    "            \"std\": \"std\",\n",
    "            \"median\": \"median\"\n",
    "        }\n",
    "\n",
    "        # Store intermediate aggregated DataFrames\n",
    "        results = []\n",
    "\n",
    "        # Loop through each aggregation function\n",
    "        for name, func in agg_funcs.items():\n",
    "            metric_ = (\n",
    "                metrics_pivot\n",
    "                # Group by model and calculate metrics (rmse, mae, smape)\n",
    "                .groupby(\"model\")[[\"rmse\", \"mae\", \"smape\"]]\n",
    "                .agg(func)  # Apply the aggregation function\n",
    "                # Rename columns to indicate the aggregation type (e.g., rmse_mean_agg)\n",
    "                .rename(columns=lambda c: f\"{c}_{name}_agg\")\n",
    "                .reset_index()  # Reset index so 'model' becomes a column again\n",
    "            )\n",
    "            # Append the aggregated DataFrame to the results list\n",
    "            results.append(metric_)\n",
    "\n",
    "        # Merge all aggregated DataFrames together on 'model'\n",
    "        metric_agg = reduce(lambda left, right: pd.merge(left, right, on=\"model\"), results)\n",
    "\n",
    "        # Merge the aggregated metrics back with the original pivot table\n",
    "        metric_summary = metrics_pivot.merge(metric_agg, on='model', how='left')\n",
    "\n",
    "        # Save Summary\n",
    "        filename = \"/base_line_metrics_summary.csv\"\n",
    "        metric_summary.to_csv(path_models + filename, index=False)\n",
    "\n",
    "        # Log all metrics in MLflow\n",
    "        metrics_list = ['rmse', 'mae', 'smape']\n",
    "        agg_types = list(agg_funcs.keys()) # ['mean', 'std', 'median']\n",
    "\n",
    "        for _, row in metric_agg.iterrows():\n",
    "            model_name = row['model']\n",
    "            \n",
    "            print(f\"\\n--- Log para o Modelo: {model_name} ---\")\n",
    "\n",
    "            for metric in metrics_list:\n",
    "                for agg in agg_types:\n",
    "                    col_name = f\"{metric}_{agg}_agg\"\n",
    "                    log_key = f\"{model_name}_{col_name}\"\n",
    "                    log_value = row[col_name]\n",
    "                    \n",
    "                    # Log no MLflow\n",
    "                    mlflow.log_metric(log_key, log_value)\n",
    "                    # print(f\"  {log_key}: {log_value:.4f}\")\n",
    "\n",
    "            # print(f\"Metrics for {model_name}: RMSE={rmse_val:.2f}, MAE={mae_val:.2f}, SMAPE={smape_val:.2f}%\")\n",
    "\n",
    "        # Best Model \n",
    "        best_model_name = metric_agg.loc[metric_agg['rmse_mean_agg'].idxmin(), 'model']\n",
    "        best_rmse = metric_agg['rmse_mean_agg'].min()\n",
    "\n",
    "        # Log best model in mlflow\n",
    "        mlflow.log_metric(\"Final_Best_RMSE_Mean_Agg\", best_rmse)\n",
    "        mlflow.set_tag(\"Best_Model_Selected\", best_model_name)\n",
    "        print(f\"Best Model: {best_model_name} with RMSE: {best_rmse:.2f}\")\n",
    "\n",
    "        # Access best pipeline\n",
    "        model_pipeline = fcst.models_[best_model_name]\n",
    "\n",
    "        # Features names extraction\n",
    "        input_data = fcst.preprocess(train, static_features=static_).head()\n",
    "\n",
    "        # Infer the model signature and dtypes\n",
    "        signature = infer_signature(input_data, model_pipeline.predict(input_data))\n",
    "\n",
    "        # Save and best model registry\n",
    "        mlflow.sklearn.log_model(\n",
    "                sk_model=model_pipeline, \n",
    "                name=f\"best_pipeline_{best_model_name}\", \n",
    "                registered_model_name=REGISTERED_MODEL_NAME, \n",
    "                signature=signature,\n",
    "                input_example=input_data.head(5)\n",
    "            )\n",
    "\n",
    "else:\n",
    "    loaded_model_uri = f\"models:/{REGISTERED_MODEL_NAME}/latest\"\n",
    "\n",
    "    # Load model\n",
    "    print(f\"Loading model from MLflow Model Registry: {loaded_model_uri}\")\n",
    "    loaded_model = mlflow.sklearn.load_model(loaded_model_uri)\n",
    "    \n",
    "    print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac8111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0802fd85",
   "metadata": {},
   "source": [
    "## Structure Future Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3322755d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['is_holiday', 'in_season', 'stock_quantity_lag1', 'stock_quantity_lag2', 'stock_quantity_lag7', 'stock_quantity_expanding_mean_lag1', 'stock_quantity_rolling_mean_lag7_window_size7'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m future_df = fcst.make_future_dataframe(h=horizon)\n\u001b[32m      3\u001b[39m regressor_cols = [\u001b[33m'\u001b[39m\u001b[33mds\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33munique_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mis_holiday\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33min_season\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstock_quantity_lag1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstock_quantity_lag2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstock_quantity_lag7\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstock_quantity_expanding_mean_lag1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mstock_quantity_rolling_mean_lag7_window_size7\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m X_regressor = \u001b[43mvalid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mregressor_cols\u001b[49m\u001b[43m]\u001b[49m.copy()\n\u001b[32m      7\u001b[39m X_df_final = future_df.merge(X_regressor, on=[\u001b[33m'\u001b[39m\u001b[33munique_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mds\u001b[39m\u001b[33m'\u001b[39m], how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_df_final.isnull().any().any():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/portfolio/smart-supply-chain-ai/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/portfolio/smart-supply-chain-ai/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/portfolio/smart-supply-chain-ai/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['is_holiday', 'in_season', 'stock_quantity_lag1', 'stock_quantity_lag2', 'stock_quantity_lag7', 'stock_quantity_expanding_mean_lag1', 'stock_quantity_rolling_mean_lag7_window_size7'] not in index\""
     ]
    }
   ],
   "source": [
    "future_df = fcst.make_future_dataframe(h=horizon)\n",
    "\n",
    "regressor_cols = ['ds', 'unique_id', 'is_holiday', 'in_season', 'stock_quantity_lag1', 'stock_quantity_lag2', 'stock_quantity_lag7', 'stock_quantity_expanding_mean_lag1', 'stock_quantity_rolling_mean_lag7_window_size7']\n",
    "\n",
    "X_regressor = valid[regressor_cols].copy()\n",
    "\n",
    "X_df_final = future_df.merge(X_regressor, on=['unique_id', 'ds'], how='left')\n",
    "\n",
    "if X_df_final.isnull().any().any():\n",
    "    print(\"ALERTA: O DataFrame X_df_final contm NaNs! Verifique a completude do seu DataFrame 'valid'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80bc485",
   "metadata": {},
   "source": [
    "### Holidays imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df285e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_holidays = holidays.country_holidays('Brazil')\n",
    "\n",
    "def classify_holiday(date):\n",
    "    if date in country_holidays:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_final['is_holiday'] = X_df_final['ds'].apply(classify_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ff3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_final[X_df_final['is_holiday'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88643f5",
   "metadata": {},
   "source": [
    "### Products Seasonality Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of JSON filenames (without extension) to be loaded\n",
    "arch_json = ['products','products_categories', 'suppliers']\n",
    "\n",
    "# Dictionary to store the loaded JSON content\n",
    "store_catalog = {}\n",
    "\n",
    "# Loop through each filename, build the full path, and load the JSON data\n",
    "for name in arch_json:\n",
    "    file_path = os.path.join(json_path, f\"{name}.json\")  # Construct full file path\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:     # Open the JSON file\n",
    "        store_catalog[name] = json.load(f)                        # Load and store the data under its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d5b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of products with product names as a column\n",
    "products = pd.DataFrame.from_dict(store_catalog['products']).T.reset_index().rename(columns={'index': 'product'})\n",
    "\n",
    "# Select variables\n",
    "products = products[['product', 'seasonality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d93d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create seasonal data\n",
    "pid = read_data.copy()\n",
    "pid = pid[['product', 'product_id']]\n",
    "pid = pid.drop_duplicates().reset_index(drop=True)\n",
    "season_products = products.merge(pid, on=['product'], how='right')\n",
    "season_products.drop(columns=['product'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79071caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge seasonal products with Future Dataframe\n",
    "X_df_final = X_df_final.merge(season_products, left_on= ['unique_id'], right_on=['product_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f96a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_seasonality(row):\n",
    "    \"\"\"\n",
    "    Checks whether the received month of a product aligns with its seasonal availability.\n",
    "    \"\"\"\n",
    "    received_month = row['month_name']\n",
    "    seasonality_list = row['seasonality']\n",
    "    \n",
    "    return received_month in seasonality_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the full month name from 'received_date' to support seasonality checks\n",
    "X_df_final['month_name'] = X_df_final['ds'].dt.month_name()\n",
    "\n",
    "# Apply function\n",
    "X_df_final['in_season'] = X_df_final.apply(check_seasonality, axis=1)\n",
    "\n",
    "# Removes the temporary column after seasonality classification is complete\n",
    "drop_cols = ['month_name', 'seasonality', 'product_id']\n",
    "X_df_final.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2045a6",
   "metadata": {},
   "source": [
    "### Stock Quantity Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_final = X_df_final.groupby('unique_id').apply(lambda g: g.ffill()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e70b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde0dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_final = X_df_final.groupby('unique_id').apply(lambda g: g.bfill()).reset_index(drop=True)\n",
    "\n",
    "X_df_final = X_df_final.sort_values(['unique_id', 'ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e178e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_final.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fcst.predict(h=horizon, X_df=X_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84696040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = valid[['ds', 'unique_id', 'y', 'category', 'sub_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.merge(preds, on=['unique_id', 'ds'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb01fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4020791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holidays\n",
    "import os\n",
    "import json\n",
    "\n",
    "class XDFPreparator:\n",
    "    \"\"\"\n",
    "    Class to prepare the X_df_final DataFrame (regressors) for mlforecast.\n",
    "    \"\"\"\n",
    "    def __init__(self, valid_df, json_path):\n",
    "        \"\"\"\n",
    "        Initializes the preparator with validation data and the path to the JSONs.\n",
    "        \n",
    "        Args:\n",
    "            valid_df (pd.DataFrame): The validation DataFrame containing already computed regressors\n",
    "                                     (lags, rolling means, etc.).\n",
    "            json_path (str): Path to the directory containing catalog JSON files \n",
    "                             (products, products_categories, etc.).\n",
    "        \"\"\"\n",
    "        self.valid_df = valid_df\n",
    "        self.json_path = json_path\n",
    "        self.store_catalog = self._load_catalog_jsons()\n",
    "        self.country_holidays = holidays.country_holidays('Brazil')\n",
    "        self.products_seasonality = self._prepare_seasonality_data()\n",
    "\n",
    "    def _load_catalog_jsons(self):\n",
    "        \"\"\"Loads the catalog JSON files.\"\"\"\n",
    "        arch_json = ['products', 'products_categories', 'suppliers']\n",
    "        catalog = {}\n",
    "        for name in arch_json:\n",
    "            file_path = os.path.join(self.json_path, f\"{name}.json\")\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                catalog[name] = json.load(f)\n",
    "        return catalog\n",
    "\n",
    "    def _prepare_seasonality_data(self):\n",
    "        \"\"\"Prepares the DataFrame with product seasonality information.\"\"\"\n",
    "        # 1. Extract seasonality from the product catalog\n",
    "        products = pd.DataFrame.from_dict(self.store_catalog['products']).T.reset_index().rename(columns={'index': 'product'})\n",
    "        products = products[['product', 'seasonality']]\n",
    "        \n",
    "        # 2. Merge with product_id from valid_df\n",
    "        # Assuming 'valid_df' has the columns 'product' and 'product_id'\n",
    "        pid = self.valid_df[['product', 'product_id']].drop_duplicates().reset_index(drop=True)\n",
    "        season_products = products.merge(pid, on=['product'], how='right')\n",
    "        season_products.drop(columns=['product'], inplace=True)\n",
    "        return season_products\n",
    "\n",
    "    def _classify_holiday(self, date):\n",
    "        \"\"\"Classifies whether a date is a national holiday.\"\"\"\n",
    "        return date in self.country_holidays\n",
    "\n",
    "    def _check_seasonality(self, row):\n",
    "        \"\"\"Checks if the row's month is in the product's seasonality list.\"\"\"\n",
    "        received_month = row['month_name']\n",
    "        seasonality_list = row['seasonality']\n",
    "        return received_month in seasonality_list\n",
    "\n",
    "    def _impute_holidays(self, df):\n",
    "        \"\"\"Imputes the 'is_holiday' column.\"\"\"\n",
    "        df['is_holiday'] = df['ds'].apply(self._classify_holiday)\n",
    "        return df\n",
    "\n",
    "    def _impute_seasonality(self, df):\n",
    "        \"\"\"Imputes the 'in_season' column.\"\"\"\n",
    "        # Merge with seasonality data\n",
    "        df = df.merge(self.products_seasonality, \n",
    "                      left_on=['unique_id'], \n",
    "                      right_on=['product_id'], \n",
    "                      how='left')\n",
    "        \n",
    "        # Create month name column\n",
    "        df['month_name'] = df['ds'].dt.month_name()\n",
    "        \n",
    "        # Apply seasonality check function\n",
    "        df['in_season'] = df.apply(self._check_seasonality, axis=1)\n",
    "        \n",
    "        # Clean up temporary columns\n",
    "        drop_cols = ['month_name', 'seasonality', 'product_id']\n",
    "        df.drop(columns=drop_cols, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def _impute_stock_quantity_lags(self, df):\n",
    "        \"\"\"Imputes lag and rolling mean columns for stock_quantity.\"\"\"\n",
    "        # Forward-fill for middle values\n",
    "        df = df.groupby('unique_id').apply(lambda g: g.ffill()).reset_index(drop=True)\n",
    "        # Backward-fill for initial values (that couldn't be filled)\n",
    "        df = df.groupby('unique_id').apply(lambda g: g.bfill()).reset_index(drop=True)\n",
    "        # Reorder at the end\n",
    "        df = df.sort_values(['unique_id', 'ds'])\n",
    "        return df\n",
    "\n",
    "    def create_future_df(self, future_df):\n",
    "        \"\"\"\n",
    "        Creates the final regressor DataFrame for mlforecast.\n",
    "\n",
    "        Args:\n",
    "            future_df (pd.DataFrame): Future DataFrame generated by fcst.make_future_dataframe(h=horizon).\n",
    "            \n",
    "        Returns:\n",
    "            pd.DataFrame: The X_df_final with all regressors filled.\n",
    "        \"\"\"\n",
    "        regressor_cols = [\n",
    "            'ds', 'unique_id', 'is_holiday', 'in_season', \n",
    "            'stock_quantity_lag1', 'stock_quantity_lag2', 'stock_quantity_lag7', \n",
    "            'stock_quantity_expanding_mean_lag1', 'stock_quantity_rolling_mean_lag7_window_size7'\n",
    "        ]\n",
    "        \n",
    "        # 1. Select and perform initial merge with existing regressors\n",
    "        X_regressor = self.valid_df[regressor_cols].copy()\n",
    "        X_df_final = future_df.merge(X_regressor, on=['unique_id', 'ds'], how='left')\n",
    "\n",
    "        if X_df_final.isnull().any().any():\n",
    "             print(\"Warning: Lag/rolling mean regressors will have NaNs in the future portion.\")\n",
    "\n",
    "        # 2. Impute Holidays\n",
    "        X_df_final = self._impute_holidays(X_df_final)\n",
    "\n",
    "        # 3. Impute Seasonality\n",
    "        X_df_final = self._impute_seasonality(X_df_final)\n",
    "        \n",
    "        # 4. Impute Lags and Rolling Means (stock_quantity)\n",
    "        X_df_final = self._impute_stock_quantity_lags(X_df_final)\n",
    "        \n",
    "        print(f\"X_df_final completed. Remaining NaNs: {X_df_final.isnull().sum().sum()}\")\n",
    "        return X_df_final\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart-supply-chain-ai-3.11 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
