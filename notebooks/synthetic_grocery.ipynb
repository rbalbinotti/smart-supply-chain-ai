{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a60ae0c",
   "metadata": {},
   "source": [
    "## Create Synthetic Dates\n",
    "\n",
    "Features of the adjusted data:\n",
    "Specific categories: Using only the categories present in your data\n",
    "\n",
    "Realistic distribution: Based on observed frequency in the provided data\n",
    "\n",
    "Realistic parameters per category:\n",
    "\n",
    "ðŸ¥¦ **Produce**\n",
    "- **Lead Time:** 1â€“3 days (locally sourced), 5â€“10 days (imported)\n",
    "- **Shelf Life:** 3â€“10 days (most fresh items), up to 2 weeks for hardy vegetables like carrots or potatoes\n",
    "\n",
    "ðŸŒ¾ **Grains and Flours**\n",
    "- **Lead Time:** 3â€“7 days (domestic), 10â€“15 days (imported specialty grains)\n",
    "- **Shelf Life:** 6 months to 1 year (dry, sealed), up to 2 years for rice and flour stored properly\n",
    "\n",
    "ðŸ§€ **Dairy and Cold Cuts**\n",
    "- **Lead Time:** 2â€“5 days (regional suppliers), 7â€“10 days (specialty cheeses)\n",
    "- **Shelf Life:**\n",
    "  - Milk & cream: 7â€“14 days refrigerated\n",
    "  - Yogurt & soft cheeses: 2â€“3 weeks\n",
    "  - Hard cheeses: 1â€“3 months\n",
    "  - Cold cuts: 1â€“2 weeks sealed\n",
    "\n",
    "â˜• **Beverages**\n",
    "- **Lead Time:** 2â€“7 days (coffee/tea distributors)\n",
    "- **Shelf Life:**\n",
    "  - Tea: 1â€“2 years (dry)\n",
    "  - Coffee beans: 6â€“12 months (sealed), 1â€“2 weeks after grinding\n",
    "  - Brewed drinks: 1â€“3 days refrigerated\n",
    "\n",
    "ðŸ¥š **Eggs and Poultry**\n",
    "- **Lead Time:** 1â€“3 days (local farms), 5â€“7 days (wholesale)\n",
    "- **Shelf Life:**\n",
    "  - Eggs: 3â€“5 weeks refrigerated\n",
    "  - Fresh poultry: 1â€“2 days raw, 3â€“4 days cooked\n",
    "\n",
    "ðŸŸ **Meats and Fish**\n",
    "- **Lead Time:** 1â€“5 days (fresh), 7â€“10 days (frozen or imported)\n",
    "- **Shelf Life:**\n",
    "  - Fresh fish: 1â€“2 days\n",
    "  - Frozen fish: 3â€“6 months\n",
    "  - Cured fish (e.g., sardines): up to 1 year\n",
    "\n",
    "ðŸ›¢ï¸ **Oils and Fats**\n",
    "- **Lead Time:** 3â€“7 days (bulk suppliers)\n",
    "- **Shelf Life:**\n",
    "  - Vegetable oils: 6â€“12 months\n",
    "  - Butter: 1 month refrigerated, 6 months frozen\n",
    "  - Coconut oil: up to 2 years\n",
    "\n",
    "ðŸ¬ **Sugars and Sweets**\n",
    "- **Lead Time:** 2â€“5 days\n",
    "- **Shelf Life:**\n",
    "  - Sugars: indefinite if dry and sealed\n",
    "  - Dried fruits (e.g., plum): 6â€“12 months\n",
    "\n",
    "ðŸª **Miscellaneous and Biscuits**\n",
    "- **Lead Time:** 2â€“6 days\n",
    "- **Shelf Life:**\n",
    "  - Biscuits: 3â€“6 months sealed\n",
    "\n",
    "\n",
    "Seasonal patterns:\n",
    "\n",
    "- Fruits/vegetables with reduced shelf life in summer\n",
    "\n",
    "- Dairy with shorter lead time in winter\n",
    "\n",
    "Realistic temporal distribution:\n",
    "\n",
    "- 80% of deliveries on weekdays\n",
    "\n",
    "Controlled outliers: Only 3% of data with unusual situations\n",
    "\n",
    "These synthetic data preserve the specific characteristics of the categories in your original dataset, with realistic temporal relationships for supply chain analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffd398",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eaf2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from smart_supply_chain_ai.utils import create_data_functions, combine_df_functions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae0d0f3",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "raw_data_path = os.path.join('../data', 'raw/')\n",
    "\n",
    "external_data_path = os.path.join('../data', 'external/')\n",
    "\n",
    "json_path = os.path.join('../src','smart_supply_chain_ai' , 'utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dab72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of JSON filenames (without extension) to be loaded\n",
    "arch_json = ['products','products_categories', 'suppliers']\n",
    "\n",
    "# Dictionary to store the loaded JSON content\n",
    "store_catalog = {}\n",
    "\n",
    "# Loop through each filename, build the full path, and load the JSON data\n",
    "for name in arch_json:\n",
    "    file_path = os.path.join(json_path, f\"{name}.json\")  # Construct full file path\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:     # Open the JSON file\n",
    "        store_catalog[name] = json.load(f)                        # Load and store the data under its name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8593090",
   "metadata": {},
   "source": [
    "# Product catalog information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e017ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of products with product names as a column\n",
    "products = pd.DataFrame.from_dict(store_catalog['products']).T.reset_index().rename(columns={'index': 'product'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c9c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace product with new IDs\n",
    "products['product_id'] = create_data_functions.create_IDs(products.shape[0], suffix='P')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760fad79",
   "metadata": {},
   "source": [
    "# Supplier catalog and distribution details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c29fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of suppliers with supplier names as a column\n",
    "suppliers = pd.DataFrame.from_dict(store_catalog['suppliers']).T.reset_index().rename(columns={'index': 'supplier'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b749c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert supplier IDs as the second column\n",
    "suppliers.insert(1, 'supplier_id', create_data_functions.create_IDs(suppliers.shape[0], suffix='S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16203de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'category' and 'subcategories' columns from the suppliers DataFrame\n",
    "suppliers.drop(columns=['category', 'subcategories'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc348105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each supplier's product list into separate rows and reset the index\n",
    "suppliers = suppliers.explode('products').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge product and supplier data on matching product names, then drop duplicate 'products' column from suppliers\n",
    "supply_df = pd.merge(products, suppliers, left_on='product', right_on='products').drop(columns='products')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc18c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random number generator with a fixed seed for reproducibility.\n",
    "rng = np.random.default_rng(seed=43)\n",
    "# Assign random supplier ratings between 1 and 4 to all suppliers.\n",
    "supply_df['supplier_rating'] = rng.integers(1, 5, size=supply_df.shape[0])\n",
    "# Randomly select 15 unique suppliers to be considered \"top suppliers\".\n",
    "suppliers_top = np.random.choice(supply_df['supplier'].unique(), 15, replace=False)\n",
    "# Update ratings: if the supplier is in the top list, set rating to 5; otherwise keep the original rating.\n",
    "supply_df['supplier_rating'] = np.where(supply_df['supplier'].isin(suppliers_top), 5, supply_df['supplier_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03561c",
   "metadata": {},
   "source": [
    "## Meteorological Data for Supply Chain Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the weather CSV file\n",
    "archive_csv = external_data_path + 'dados_83967_D_2015-01-01_2025-09-18.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "weather_df = pd.read_csv(archive_csv, sep=\";\", decimal=\",\", skiprows=9, engine=\"python\")\n",
    "\n",
    "# Show the first rows of the DataFrame\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b992108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that contain only missing values\n",
    "weather_df.dropna(axis=1, how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efbb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to clear and descriptive English names\n",
    "weather_df.columns = [\n",
    "    \"measurement_date\",\n",
    "    \"daily_total_precipitation_mm\",\n",
    "    \"daily_maximum_temperature_c\",\n",
    "    \"daily_minimum_temperature_c\",\n",
    "    \"daily_average_wind_speed_mps\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3610680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'measurement_date' as index and remove rows with all missing values\n",
    "weather_df.set_index('measurement_date').dropna(how='all', inplace=True)\n",
    "\n",
    "# Show the first rows of the DataFrame\n",
    "weather_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'measurement_date' column to datetime format\n",
    "weather_df['measurement_date'] = pd.to_datetime(weather_df['measurement_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364d4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary information about the DataFrame\n",
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped all missing values\n",
    "weather_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the weather classification function to the cleaned DataFrame to generate severity and category labels\n",
    "weather_severity_df = create_data_functions.classify_weather(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5686c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 10 samples rows of the DataFrame\n",
    "weather_severity_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and transpose summary statistics for all numeric columns in the classified weather DataFrame\n",
    "weather_severity_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start date of the time range\n",
    "start_date = pd.to_datetime('2020-01-01')\n",
    "\n",
    "# Define the end date\n",
    "end_date = pd.to_datetime('2025-01-05')\n",
    "\n",
    "# Create a daily date range from start_date to end_date\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Specify the number of rows in the dataset (i.e., total number of records to generate)\n",
    "n_rows = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b765a7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample dates from the date range\n",
    "random_dates = np.random.choice(date_range, size=n_rows, replace=True)\n",
    "\n",
    "# Create a DataFrame with the sampled dates\n",
    "date_df = pd.DataFrame({\n",
    "    'LPO': random_dates\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the day classification function to each value in the 'LPO' (latest_purchase_order) column and store the result in a new column\n",
    "date_df['day_classification'] = date_df['LPO'].apply(create_data_functions.day_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge weather severity data into the date DataFrame based on matching dates ('LPO' (latest_purchase_order) and 'measurement_date'),\n",
    "# then drop the redundant 'measurement_date' column after the join\n",
    "climate_date_df = pd.merge(date_df, weather_severity_df, left_on='LPO', right_on='measurement_date', how='inner').drop(columns='measurement_date')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f44b25",
   "metadata": {},
   "source": [
    "# Realistic supply chain modeling based on weather and product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the climate data DataFrame to work with weather-specific analysis\n",
    "df_weather = climate_date_df.copy()\n",
    "\n",
    "# Create a copy of the supply data DataFrame to work with product-related operations\n",
    "df_products = supply_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first row of the weather DataFrame to preview its structure\n",
    "df_weather.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e4ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first row of the products DataFrame to check column names and initial data\n",
    "df_products.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f109ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna 'LPO' para o formato datetime\n",
    "df_weather['LPO'] = pd.to_datetime(df_weather['LPO'])\n",
    "\n",
    "# Extrair o nÃºmero do mÃªs da data\n",
    "df_weather['month'] = df_weather['LPO'].dt.month\n",
    "\n",
    "# Extrair o nome do mÃªs (ex: Janeiro, Fevereiro)\n",
    "df_weather['month_name'] = df_weather['LPO'].dt.month_name()\n",
    "\n",
    "# Extrair o nome do dia da semana (ex: Segunda-feira)\n",
    "df_weather['day_of_week'] = df_weather['LPO'].dt.day_name()\n",
    "\n",
    "# Extrair o nÃºmero do dia do mÃªs\n",
    "df_weather['day_of_month'] = df_weather['LPO'].dt.day\n",
    "\n",
    "# Criar uma coluna booleana indicando se o dia Ã© feriado\n",
    "df_weather['is_holiday'] = np.where(df_weather['day_classification'] == 'Holiday', True, False)\n",
    "\n",
    "# Criar uma coluna booleana indicando se o dia Ã© fim de semana (sÃ¡bado ou domingo)\n",
    "df_weather['is_weekend'] = np.where(df_weather['LPO'].dt.dayofweek > 4, True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the weather DataFrame\n",
    "df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the products DataFrame\n",
    "df_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f60ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the supply chain simulator with weather and product data,\n",
    "# then run the simulation to generate a combined DataFrame with results.\n",
    "simulator = combine_df_functions.SupplyChainSimulator(df_weather, df_products)\n",
    "df_combined = simulator.run_simulation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77962f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a delivery plan with up to 5 products per day.\n",
    "# Allows 30% of products to be out-of-season.\n",
    "deliveries, stats = simulator.create_balanced_delivery(max_products_per_day=5, out_of_season_percentage=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f0694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "deliveries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759263c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data\n",
    "deliveries.to_csv(raw_data_path + 'grocery_data.csv', index=False)\n",
    "stats.to_csv(raw_data_path + 'grocery_stats.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart-supply-chain-ai-3.11 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
